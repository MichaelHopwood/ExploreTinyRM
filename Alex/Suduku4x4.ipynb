{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.0\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import exploretinyrm as m\n",
    "print(m.__version__)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from exploretinyrm.utils import compute_tensor_summary  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, math, random\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "\n",
    "from exploretinyrm.trm import TRM, TRMConfig\n",
    "\n",
    "def set_seed(seed: int = 123):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(123)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset (puzzle, solution)\n",
    "\n",
    "SIDE = 4\n",
    "BASE = 2\n",
    "INPUT_PAD = 0               # 0 marks blank in the INPUT ONLY\n",
    "INPUT_TOKENS = SIDE + 1     # {0..4} for inputs\n",
    "OUTPUT_TOKENS = SIDE        # {0..3} for outputs (represents digits 1..4)\n",
    "\n",
    "BASE_SOLUTION = np.array([\n",
    "    [1, 2, 3, 4],\n",
    "    [3, 4, 1, 2],\n",
    "    [2, 1, 4, 3],\n",
    "    [4, 3, 2, 1],\n",
    "], dtype=np.int64)\n",
    "\n",
    "def permute_solution(board: np.ndarray, rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"random legal permutations: rows/cols within bands/stacks, swap bands/stacks, digit perm\"\"\"\n",
    "    b = BASE; s = SIDE\n",
    "    # rows within bands\n",
    "    row_idx = []\n",
    "    bands = [list(range(g*b, (g+1)*b)) for g in range(b)]\n",
    "    for band in bands:\n",
    "        rng.shuffle(band); row_idx.extend(band)\n",
    "    board = board[row_idx, :]\n",
    "    # cols within stacks\n",
    "    col_idx = []\n",
    "    stacks = [list(range(g*b, (g+1)*b)) for g in range(b)]\n",
    "    for stack in stacks:\n",
    "        rng.shuffle(stack); col_idx.extend(stack)\n",
    "    board = board[:, col_idx]\n",
    "    # swap bands\n",
    "    band_order = list(range(b)); rng.shuffle(band_order)\n",
    "    row_idx = []\n",
    "    for g in band_order: row_idx.extend(list(range(g*b, (g+1)*b)))\n",
    "    board = board[row_idx, :]\n",
    "    # swap stacks\n",
    "    stack_order = list(range(b)); rng.shuffle(stack_order)\n",
    "    col_idx = []\n",
    "    for g in stack_order: col_idx.extend(list(range(g*b, (g+1)*b)))\n",
    "    board = board[:, col_idx]\n",
    "    # permute digits 1..SIDE\n",
    "    digits = np.arange(1, s+1); rng.shuffle(digits)\n",
    "    mapping = {i+1: digits[i] for i in range(s)}\n",
    "    return np.vectorize(lambda v: mapping[v])(board)\n",
    "\n",
    "def make_puzzle(solution: np.ndarray, p_blank: float, rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"mask entries with probability p_blank to form the puzzle\"\"\"\n",
    "    mask = rng.random(solution.shape) < p_blank\n",
    "    puzzle = solution.copy()\n",
    "    puzzle[mask] = INPUT_PAD\n",
    "    return puzzle\n",
    "\n",
    "\n",
    "class Sudoku4x4(Dataset):\n",
    "    def __init__(self, n_samples: int, p_blank: float = 0.5, seed: int = 0):\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        self.samples = []\n",
    "        for _ in range(n_samples):\n",
    "            sol = permute_solution(BASE_SOLUTION, self.rng)     # digits in 1..4\n",
    "            puz = make_puzzle(sol, p_blank=p_blank, rng=self.rng)\n",
    "            x_tokens = puz.reshape(-1).astype(np.int64)         # [16], values in {0..4}\n",
    "            y_digits = sol.reshape(-1).astype(np.int64)         # [16], values in {1..4}\n",
    "            y_tokens = (y_digits - 1)                           # map to {0..3} for CE\n",
    "            self.samples.append((x_tokens, y_tokens))\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.samples[idx]\n",
    "        return torch.from_numpy(x), torch.from_numpy(y)\n",
    "\n",
    "def get_loaders(n_train=512, n_val=128, batch_size=16, p_blank=0.45, seed=123):\n",
    "    # slightly easier p_blank for the first sanity run; you can return to 0.50 after it learns\n",
    "    ds_tr = Sudoku4x4(n_train, p_blank=p_blank, seed=seed)\n",
    "    ds_va = Sudoku4x4(n_val,   p_blank=p_blank, seed=seed+1)\n",
    "    return (\n",
    "        DataLoader(ds_tr, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True),\n",
    "        DataLoader(ds_va, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "    )\n",
    "\n",
    "train_loader, val_loader = get_loaders(\n",
    "    n_train=4096, \n",
    "    n_val=512,\n",
    "    batch_size=16,\n",
    "    p_blank=0.50,\n",
    "    seed=123\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity OK: x in [0,SIDE], y in [0,SIDE-1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ensure labels are in 0 to 3 and inputs are in 0to4\n",
    "bx, by = next(iter(train_loader))\n",
    "assert bx.min().item() >= 0 and bx.max().item() <= SIDE\n",
    "assert by.min().item() >= 0 and by.max().item() < SIDE\n",
    "print(\"Sanity OK: x in [0,SIDE], y in [0,SIDE-1]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params (M): 0.889856\n"
     ]
    }
   ],
   "source": [
    "# keep SIDE, SEQ_LEN, USE_ATT as before\n",
    "D_MODEL = 192\n",
    "SEQ_LEN = SIDE * SIDE\n",
    "N_SUP   = 16          # paper uses \"up to 16\" for Sudoku\n",
    "N       = 6  # of z-updates inside a recursion process\n",
    "T       = 3  # of full recursion processes per supervision step\n",
    "USE_ATT = False # false for SUDUKU ONLY !!!!!!!\n",
    "\n",
    "\n",
    "cfg = TRMConfig(\n",
    "    input_vocab_size=INPUT_TOKENS,  # 5\n",
    "    output_vocab_size=OUTPUT_TOKENS,  # 4\n",
    "    seq_len=SEQ_LEN,\n",
    "    d_model=D_MODEL,\n",
    "    n_layers=2,   \n",
    "    use_attention=USE_ATT, # token MLP for SUDUKU\n",
    "    n_heads=8,        # ignored when use_attention=False; harmless but see note below\n",
    "    dropout=0.0,\n",
    "    mlp_ratio=4.0,\n",
    "    token_mlp_ratio=2.0,\n",
    "    n=N,\n",
    "    T=T,\n",
    "    k_last_ops=None,\n",
    "    stabilize_input_sums = True #False to be like the paper but here produces NaN !!!\n",
    ")\n",
    "\n",
    "model = TRM(cfg).to(device)\n",
    "print(\"Params (M):\", sum(p.numel() for p in model.parameters())/1e6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from torch.amp import autocast, GradScaler\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "\n",
    "def exact_match_from_logits(logits: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "    # logits: [B, L, V], y_true: [B, L]\n",
    "    preds = logits.argmax(dim=-1)                      # [B, L]\n",
    "    return (preds == y_true).all(dim=1).float()        # [B]\n",
    "\n",
    "def token_ce_loss(logits: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "    # flatten to (B*L, V) vs (B*L)\n",
    "    B, L, V = logits.shape\n",
    "    return F.cross_entropy(logits.reshape(B*L, V), y_true.reshape(B*L))\n",
    "\n",
    "\n",
    "def train_one_epoch(model: TRM, loader: DataLoader, optimizer, scaler, epoch: int, use_amp: bool = True):\n",
    "    model.train()\n",
    "    total_ce, total_halt, total_em, total_steps = 0.0, 0.0, 0.0, 0\n",
    "\n",
    "    for x_tokens, y_true in loader:\n",
    "        x_tokens = x_tokens.to(device, non_blocking=True)\n",
    "        y_true   = y_true.to(device,   non_blocking=True)   # tokens in {0..3}\n",
    "\n",
    "        y_state, z_state = model.init_state(batch_size=x_tokens.size(0), device=device)\n",
    "\n",
    "        for _ in range(N_SUP):\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            #with autocast(\"cuda\", enabled=(device.type == \"cuda\" and use_amp)):\n",
    "            y_state, z_state, logits, halt_logit = model.forward_step(\n",
    "                x_tokens, y=y_state, z=z_state, n=N, T=T, k_last_ops=None  # truncation helps early training (paper said it is failed idea)\n",
    "            )\n",
    "            # stable losses in fp32\n",
    "            loss_ce   = token_ce_loss(logits.float(), y_true)\n",
    "            with torch.no_grad():\n",
    "                em = exact_match_from_logits(logits, y_true)\n",
    "\n",
    "            loss_halt = F.binary_cross_entropy_with_logits(halt_logit.float(), em)\n",
    "            loss = loss_ce + loss_halt\n",
    "\n",
    "            if use_amp:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(optimizer) # unscale before clipping\n",
    "                clip_grad_norm_(model.parameters(), 1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "            total_ce   += loss_ce.detach().item()\n",
    "            total_halt += loss_halt.detach().item()\n",
    "            total_em   += em.mean().item()\n",
    "            total_steps += 1\n",
    "\n",
    "            # if (halt_logit > 0).all():\n",
    "            #    break\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | CE {total_ce/max(1,total_steps):.4f} | HaltBCE {total_halt/max(1,total_steps):.4f} | Exact-match {total_em/max(1,total_steps):.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model: TRM, loader: DataLoader, n_sup_eval: int = N_SUP):\n",
    "    model.eval()\n",
    "    em_list, cell_acc_list = [], []\n",
    "\n",
    "    for x_tokens, y_true in loader:\n",
    "        x_tokens = x_tokens.to(device)\n",
    "        y_true   = y_true.to(device)\n",
    "        y_state, z_state = model.init_state(batch_size=x_tokens.size(0), device=device)\n",
    "\n",
    "        for _ in range(n_sup_eval):\n",
    "            y_state, z_state, logits, halt_logit = model.forward_step(\n",
    "                x_tokens, y=y_state, z=z_state, n=N, T=T, k_last_ops=None  # make eval consistent\n",
    "            )\n",
    "\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        em = (preds == y_true).all(dim=1).float()\n",
    "        cell_acc = (preds == y_true).float().mean(dim=1)\n",
    "        em_list.append(em); cell_acc_list.append(cell_acc)\n",
    "\n",
    "    em = torch.cat(em_list).mean().item()\n",
    "    cell_acc = torch.cat(cell_acc_list).mean().item()\n",
    "    print(f\"Validation | Exact-match {em:.3f} | Cell accuracy {cell_acc:.3f}\")\n",
    "    return em, cell_acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.0, betas=(0.9, 0.95))\n",
    "scaler = GradScaler(\"cuda\", enabled=(device.type == \"cuda\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward-only finiteness: y1 True z1 True logits True halt_logit True\n",
      "Pre-backward finiteness: loss True loss_ce True loss_halt True\n",
      "Gradients finite: True\n",
      "Post-step forward finiteness: y2 True z2 True logits2 True halt2 True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# one batch\n",
    "x_tokens, y_true = next(iter(train_loader))\n",
    "x_tokens = x_tokens.to(device)\n",
    "y_true   = y_true.to(device)\n",
    "\n",
    "# forward-only check (no training, no AMP)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y0, z0 = model.init_state(batch_size=x_tokens.size(0), device=device)\n",
    "    y1, z1, logits, halt_logit = model.forward_step(x_tokens, y=y0, z=z0, n=N, T=T, k_last_ops=None)\n",
    "print(\"Forward-only finiteness:\",\n",
    "      \"y1\", torch.isfinite(y1).all().item(),\n",
    "      \"z1\", torch.isfinite(z1).all().item(),\n",
    "      \"logits\", torch.isfinite(logits).all().item(),\n",
    "      \"halt_logit\", torch.isfinite(halt_logit).all().item())\n",
    "\n",
    "# single training step in full FP32 (no AMP, tiny LR, no weight decay)\n",
    "model.train()\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.0)\n",
    "opt.zero_grad(set_to_none=True)\n",
    "\n",
    "y0, z0 = model.init_state(batch_size=x_tokens.size(0), device=device)\n",
    "y1, z1, logits, halt_logit = model.forward_step(x_tokens, y=y0, z=z0, n=N, T=T, k_last_ops=None)\n",
    "\n",
    "# compute losses in fp32\n",
    "loss_ce = F.cross_entropy(logits.float().reshape(-1, OUTPUT_TOKENS), y_true.reshape(-1))\n",
    "em = (logits.argmax(dim=-1) == y_true).all(dim=1).float()\n",
    "loss_halt = F.binary_cross_entropy_with_logits(halt_logit.float(), em)\n",
    "loss = loss_ce + loss_halt\n",
    "\n",
    "print(\"Pre-backward finiteness:\",\n",
    "      \"loss\", torch.isfinite(loss).item(),\n",
    "      \"loss_ce\", torch.isfinite(loss_ce).item(),\n",
    "      \"loss_halt\", torch.isfinite(loss_halt).item())\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "# check grads\n",
    "all_grads_finite = True\n",
    "for n, p in model.named_parameters():\n",
    "    if p.grad is None:\n",
    "        continue\n",
    "    if not torch.isfinite(p.grad).all():\n",
    "        print(\"Non-finite grad in:\", n)\n",
    "        all_grads_finite = False\n",
    "        break\n",
    "print(\"Gradients finite:\", all_grads_finite)\n",
    "\n",
    "# clip and step\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "opt.step()\n",
    "\n",
    "# forward again after one small step\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y0, z0 = model.init_state(batch_size=x_tokens.size(0), device=device)\n",
    "    y2, z2, logits2, halt2 = model.forward_step(x_tokens, y=y0, z=z0, n=N, T=T, k_last_ops=None)\n",
    "print(\"Post-step forward finiteness:\",\n",
    "      \"y2\", torch.isfinite(y2).all().item(),\n",
    "      \"z2\", torch.isfinite(z2).all().item(),\n",
    "      \"logits2\", torch.isfinite(logits2).all().item(),\n",
    "      \"halt2\", torch.isfinite(halt2).all().item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | CE 0.3163 | HaltBCE 0.4436 | Exact-match 0.359\n",
      "Validation | Exact-match 0.525 | Cell accuracy 0.922\n",
      "Epoch 02 | CE 0.2096 | HaltBCE 0.4966 | Exact-match 0.553\n",
      "Validation | Exact-match 0.570 | Cell accuracy 0.926\n",
      "Epoch 03 | CE 0.2193 | HaltBCE 0.4925 | Exact-match 0.581\n",
      "Validation | Exact-match 0.555 | Cell accuracy 0.918\n",
      "Epoch 04 | CE 0.2190 | HaltBCE 0.4549 | Exact-match 0.602\n",
      "Validation | Exact-match 0.566 | Cell accuracy 0.916\n",
      "Epoch 05 | CE 0.2093 | HaltBCE 0.4560 | Exact-match 0.598\n",
      "Validation | Exact-match 0.475 | Cell accuracy 0.913\n",
      "Epoch 06 | CE 0.2180 | HaltBCE 0.4385 | Exact-match 0.613\n",
      "Validation | Exact-match 0.605 | Cell accuracy 0.929\n",
      "Epoch 07 | CE 0.2095 | HaltBCE 0.4274 | Exact-match 0.623\n",
      "Validation | Exact-match 0.670 | Cell accuracy 0.931\n",
      "Epoch 08 | CE 0.2179 | HaltBCE 0.4308 | Exact-match 0.663\n",
      "Validation | Exact-match 0.658 | Cell accuracy 0.926\n",
      "Epoch 09 | CE 0.2128 | HaltBCE 0.4090 | Exact-match 0.678\n",
      "Validation | Exact-match 0.684 | Cell accuracy 0.930\n",
      "Epoch 10 | CE 0.2330 | HaltBCE 0.4146 | Exact-match 0.670\n",
      "Validation | Exact-match 0.672 | Cell accuracy 0.922\n"
     ]
    }
   ],
   "source": [
    "# train+eval\n",
    "EPOCHS = 10\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train_one_epoch(model, train_loader, optimizer, scaler, epoch, use_amp=False)\n",
    "    evaluate(model, val_loader, n_sup_eval=N_SUP)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Puzzle 0:\n",
      "[[3 0 1 0]\n",
      " [0 0 0 2]\n",
      " [0 1 2 3]\n",
      " [2 0 0 1]]\n",
      "Pred:\n",
      "[[3 2 1 4]\n",
      " [1 4 3 2]\n",
      " [4 1 2 3]\n",
      " [2 3 4 1]]\n",
      "True:\n",
      "[[3 2 1 4]\n",
      " [1 4 3 2]\n",
      " [4 1 2 3]\n",
      " [2 3 4 1]]\n",
      "\n",
      "Puzzle 1:\n",
      "[[0 0 0 4]\n",
      " [4 0 3 1]\n",
      " [0 4 1 3]\n",
      " [0 1 4 2]]\n",
      "Pred:\n",
      "[[1 3 2 4]\n",
      " [4 2 3 1]\n",
      " [2 4 1 3]\n",
      " [3 1 4 2]]\n",
      "True:\n",
      "[[1 3 2 4]\n",
      " [4 2 3 1]\n",
      " [2 4 1 3]\n",
      " [3 1 4 2]]\n",
      "\n",
      "Puzzle 2:\n",
      "[[0 4 0 1]\n",
      " [0 0 3 4]\n",
      " [0 2 4 3]\n",
      " [4 3 1 0]]\n",
      "Pred:\n",
      "[[3 4 2 1]\n",
      " [2 1 3 4]\n",
      " [1 2 4 3]\n",
      " [4 3 1 2]]\n",
      "True:\n",
      "[[3 4 2 1]\n",
      " [2 1 3 4]\n",
      " [1 2 4 3]\n",
      " [4 3 1 2]]\n",
      "\n",
      "Puzzle 3:\n",
      "[[0 0 4 2]\n",
      " [0 4 3 1]\n",
      " [4 0 1 3]\n",
      " [3 0 0 4]]\n",
      "Pred:\n",
      "[[1 3 4 2]\n",
      " [2 4 3 1]\n",
      " [4 2 1 3]\n",
      " [3 1 2 4]]\n",
      "True:\n",
      "[[1 3 4 2]\n",
      " [2 4 3 1]\n",
      " [4 2 1 3]\n",
      " [3 1 2 4]]\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def solve_and_show(model: TRM, loader: DataLoader, n_batches: int = 1):\n",
    "    model.eval()\n",
    "    shown = 0\n",
    "    for x_tokens, y_true in loader:\n",
    "        x_tokens = x_tokens.to(device)\n",
    "        y_true   = y_true.to(device)\n",
    "        y_state, z_state = model.init_state(batch_size=x_tokens.size(0), device=device)\n",
    "        for _ in range(N_SUP):\n",
    "            y_state, z_state, logits, halt_logit = model.forward_step(\n",
    "                x_tokens, y=y_state, z=z_state, n=N, T=T, k_last_ops=None\n",
    "            )\n",
    "        preds_tok = logits.argmax(dim=-1).cpu().numpy()\n",
    "        xs = x_tokens.cpu().numpy()\n",
    "        ys_tok = y_true.cpu().numpy()\n",
    "        for i in range(min(4, xs.shape[0])):\n",
    "            print(f\"\\nPuzzle {shown+i}:\")\n",
    "            print(xs[i].reshape(4,4))\n",
    "            print(\"Pred:\")\n",
    "            print((preds_tok[i] + 1).reshape(4,4))   # tokens -> digits\n",
    "            print(\"True:\")\n",
    "            print((ys_tok[i] + 1).reshape(4,4))\n",
    "        shown += 1\n",
    "        if shown >= n_batches:\n",
    "            break\n",
    "\n",
    "solve_and_show(model, val_loader, n_batches=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
