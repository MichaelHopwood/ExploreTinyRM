{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.0\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import exploretinyrm as m\n",
    "print(m.__version__)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from exploretinyrm.utils import compute_tensor_summary  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, math, random\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "\n",
    "from exploretinyrm.trm import TRM, TRMConfig\n",
    "\n",
    "def set_seed(seed: int = 123):\n",
    "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(123)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset (puzzle, solution)\n",
    "\n",
    "SIDE = 4\n",
    "BASE = 2\n",
    "INPUT_PAD = 0               # 0 marks blank in the INPUT ONLY\n",
    "INPUT_TOKENS = SIDE + 1     # {0..4} for inputs\n",
    "OUTPUT_TOKENS = SIDE        # {0..3} for outputs (represents digits 1..4)\n",
    "\n",
    "BASE_SOLUTION = np.array([\n",
    "    [1, 2, 3, 4],\n",
    "    [3, 4, 1, 2],\n",
    "    [2, 1, 4, 3],\n",
    "    [4, 3, 2, 1],\n",
    "], dtype=np.int64)\n",
    "\n",
    "def permute_solution(board: np.ndarray, rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"random legal permutations: rows/cols within bands/stacks, swap bands/stacks, digit perm\"\"\"\n",
    "    b = BASE; s = SIDE\n",
    "    # rows within bands\n",
    "    row_idx = []\n",
    "    bands = [list(range(g*b, (g+1)*b)) for g in range(b)]\n",
    "    for band in bands:\n",
    "        rng.shuffle(band); row_idx.extend(band)\n",
    "    board = board[row_idx, :]\n",
    "    # cols within stacks\n",
    "    col_idx = []\n",
    "    stacks = [list(range(g*b, (g+1)*b)) for g in range(b)]\n",
    "    for stack in stacks:\n",
    "        rng.shuffle(stack); col_idx.extend(stack)\n",
    "    board = board[:, col_idx]\n",
    "    # swap bands\n",
    "    band_order = list(range(b)); rng.shuffle(band_order)\n",
    "    row_idx = []\n",
    "    for g in band_order: row_idx.extend(list(range(g*b, (g+1)*b)))\n",
    "    board = board[row_idx, :]\n",
    "    # swap stacks\n",
    "    stack_order = list(range(b)); rng.shuffle(stack_order)\n",
    "    col_idx = []\n",
    "    for g in stack_order: col_idx.extend(list(range(g*b, (g+1)*b)))\n",
    "    board = board[:, col_idx]\n",
    "    # permute digits 1..SIDE\n",
    "    digits = np.arange(1, s+1); rng.shuffle(digits)\n",
    "    mapping = {i+1: digits[i] for i in range(s)}\n",
    "    return np.vectorize(lambda v: mapping[v])(board)\n",
    "\n",
    "def make_puzzle(solution: np.ndarray, p_blank: float, rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"mask entries with probability p_blank to form the puzzle\"\"\"\n",
    "    mask = rng.random(solution.shape) < p_blank\n",
    "    puzzle = solution.copy()\n",
    "    puzzle[mask] = INPUT_PAD\n",
    "    return puzzle\n",
    "\n",
    "\n",
    "class Sudoku4x4(Dataset):\n",
    "    def __init__(self, n_samples: int, p_blank: float = 0.5, seed: int = 0):\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        self.samples = []\n",
    "        for _ in range(n_samples):\n",
    "            sol = permute_solution(BASE_SOLUTION, self.rng)     # digits in 1..4\n",
    "            puz = make_puzzle(sol, p_blank=p_blank, rng=self.rng)\n",
    "            x_tokens = puz.reshape(-1).astype(np.int64)         # [16], values in {0..4}\n",
    "            y_digits = sol.reshape(-1).astype(np.int64)         # [16], values in {1..4}\n",
    "            y_tokens = (y_digits - 1)                           # map to {0..3} for CE\n",
    "            self.samples.append((x_tokens, y_tokens))\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.samples[idx]\n",
    "        return torch.from_numpy(x), torch.from_numpy(y)\n",
    "\n",
    "def get_loaders(n_train=512, n_val=128, batch_size=16, p_blank=0.45, seed=123):\n",
    "    # slightly easier p_blank for the first sanity run; you can return to 0.50 after it learns\n",
    "    ds_tr = Sudoku4x4(n_train, p_blank=p_blank, seed=seed)\n",
    "    ds_va = Sudoku4x4(n_val,   p_blank=p_blank, seed=seed+1)\n",
    "    return (\n",
    "        DataLoader(ds_tr, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True),\n",
    "        DataLoader(ds_va, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "    )\n",
    "\n",
    "train_loader, val_loader = get_loaders(\n",
    "    n_train=2048, #4096\n",
    "    n_val=512,\n",
    "    batch_size=16,\n",
    "    p_blank=0.50,\n",
    "    seed=123\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity OK: x in [0,SIDE], y in [0,SIDE-1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ensure labels are in 0 to 3 and inputs are in 0to4\n",
    "bx, by = next(iter(train_loader))\n",
    "assert bx.min().item() >= 0 and bx.max().item() <= SIDE\n",
    "assert by.min().item() >= 0 and by.max().item() < SIDE\n",
    "print(\"Sanity OK: x in [0,SIDE], y in [0,SIDE-1]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to create tensor with negative dimension -14: [5, -14]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m      7\u001b[39m USE_ATT = \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;66;03m# false for SUDUKU ONLY !!!!!!!\u001b[39;00m\n\u001b[32m     10\u001b[39m cfg = TRMConfig(\n\u001b[32m     11\u001b[39m     input_vocab_size=INPUT_TOKENS,  \u001b[38;5;66;03m# 5\u001b[39;00m\n\u001b[32m     12\u001b[39m     output_vocab_size=OUTPUT_TOKENS,  \u001b[38;5;66;03m# 4\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m     stabilize_input_sums = \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;66;03m#False to be like the paper but here produces NaN !!!\u001b[39;00m\n\u001b[32m     25\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m model = \u001b[43mTRM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mParams (M):\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28msum\u001b[39m(p.numel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model.parameters())/\u001b[32m1e6\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/repos/ExploreTinyRM/src/exploretinyrm/trm.py:287\u001b[39m, in \u001b[36mTRM.__init__\u001b[39m\u001b[34m(self, cfg)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28mself\u001b[39m.cfg = cfg\n\u001b[32m    286\u001b[39m \u001b[38;5;66;03m# input embedding and output head (reverse embedding)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28mself\u001b[39m.input_emb = \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput_vocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43md_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[38;5;28mself\u001b[39m.shared_net = TinySharedNet(\n\u001b[32m    289\u001b[39m     d_model=cfg.d_model,\n\u001b[32m    290\u001b[39m     seq_len=cfg.seq_len,\n\u001b[32m   (...)\u001b[39m\u001b[32m    296\u001b[39m     token_mlp_ratio=cfg.token_mlp_ratio,\n\u001b[32m    297\u001b[39m )\n\u001b[32m    298\u001b[39m \u001b[38;5;28mself\u001b[39m.output_head = OutputHead(cfg.d_model, cfg.output_vocab_size)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/repos/ExploreTinyRM/.venv/lib/python3.12/site-packages/torch/nn/modules/sparse.py:169\u001b[39m, in \u001b[36mEmbedding.__init__\u001b[39m\u001b[34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight, _freeze, device, dtype)\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;28mself\u001b[39m.scale_grad_by_freq = scale_grad_by_freq\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    168\u001b[39m     \u001b[38;5;28mself\u001b[39m.weight = Parameter(\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m         \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    170\u001b[39m         requires_grad=\u001b[38;5;129;01mnot\u001b[39;00m _freeze,\n\u001b[32m    171\u001b[39m     )\n\u001b[32m    172\u001b[39m     \u001b[38;5;28mself\u001b[39m.reset_parameters()\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mRuntimeError\u001b[39m: Trying to create tensor with negative dimension -14: [5, -14]"
     ]
    }
   ],
   "source": [
    "# keep SIDE, SEQ_LEN, USE_ATT as before\n",
    "D_MODEL = 14-28\n",
    "SEQ_LEN = SIDE * SIDE\n",
    "N_SUP   = 16          # paper uses \"up to 16\" for Sudoku\n",
    "N       = 6  # of z-updates inside a recursion process\n",
    "T       = 3  # of full recursion processes per supervision step\n",
    "USE_ATT = False # false for SUDUKU ONLY !!!!!!!\n",
    "\n",
    "\n",
    "cfg = TRMConfig(\n",
    "    input_vocab_size=INPUT_TOKENS,  # 5\n",
    "    output_vocab_size=OUTPUT_TOKENS,  # 4\n",
    "    seq_len=SEQ_LEN,\n",
    "    d_model=D_MODEL,\n",
    "    n_layers=2,   \n",
    "    use_attention=USE_ATT, # token MLP for SUDUKU\n",
    "    n_heads=8,        # ignored when use_attention=False; harmless but see note below\n",
    "    dropout=0.0,\n",
    "    mlp_ratio=4.0,\n",
    "    token_mlp_ratio=2.0,\n",
    "    n=N,\n",
    "    T=T,\n",
    "    k_last_ops=None,\n",
    "    stabilize_input_sums = True #False to be like the paper but here produces NaN !!!\n",
    ")\n",
    "\n",
    "model = TRM(cfg).to(device)\n",
    "print(\"Params (M):\", sum(p.numel() for p in model.parameters())/1e6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from torch.amp import autocast, GradScaler\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "\n",
    "def exact_match_from_logits(logits: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "    # logits: [B, L, V], y_true: [B, L]\n",
    "    preds = logits.argmax(dim=-1)                      # [B, L]\n",
    "    return (preds == y_true).all(dim=1).float()        # [B]\n",
    "\n",
    "def token_ce_loss(logits: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "    # flatten to (B*L, V) vs (B*L)\n",
    "    B, L, V = logits.shape\n",
    "    return F.cross_entropy(logits.reshape(B*L, V), y_true.reshape(B*L))\n",
    "\n",
    "\n",
    "def train_one_epoch(model: TRM, loader: DataLoader, optimizer, scaler, epoch: int, use_amp: bool = True):\n",
    "    model.train()\n",
    "    total_ce, total_halt, total_em, total_steps = 0.0, 0.0, 0.0, 0\n",
    "\n",
    "    for x_tokens, y_true in loader:\n",
    "        x_tokens = x_tokens.to(device, non_blocking=True)\n",
    "        y_true   = y_true.to(device,   non_blocking=True)   # tokens in {0..3}\n",
    "\n",
    "        y_state, z_state = model.init_state(batch_size=x_tokens.size(0), device=device)\n",
    "\n",
    "        for _ in range(N_SUP):\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            #with autocast(\"cuda\", enabled=(device.type == \"cuda\" and use_amp)):\n",
    "            y_state, z_state, logits, halt_logit = model.forward_step(\n",
    "                x_tokens, y=y_state, z=z_state, n=N, T=T, k_last_ops=None  # truncation helps early training (paper said it is failed idea)\n",
    "            )\n",
    "            # stable losses in fp32\n",
    "            loss_ce   = token_ce_loss(logits.float(), y_true)\n",
    "            with torch.no_grad():\n",
    "                em = exact_match_from_logits(logits, y_true)\n",
    "\n",
    "            loss_halt = F.binary_cross_entropy_with_logits(halt_logit.float(), em)\n",
    "            loss = loss_ce + loss_halt\n",
    "\n",
    "            if use_amp:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(optimizer) # unscale before clipping\n",
    "                clip_grad_norm_(model.parameters(), 1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "            total_ce   += loss_ce.detach().item()\n",
    "            total_halt += loss_halt.detach().item()\n",
    "            total_em   += em.mean().item()\n",
    "            total_steps += 1\n",
    "\n",
    "            # if (halt_logit > 0).all():\n",
    "            #    break\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | CE {total_ce/max(1,total_steps):.4f} | HaltBCE {total_halt/max(1,total_steps):.4f} | Exact-match {total_em/max(1,total_steps):.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model: TRM, loader: DataLoader, n_sup_eval: int = N_SUP):\n",
    "    model.eval()\n",
    "    em_list, cell_acc_list = [], []\n",
    "\n",
    "    for x_tokens, y_true in loader:\n",
    "        x_tokens = x_tokens.to(device)\n",
    "        y_true   = y_true.to(device)\n",
    "        y_state, z_state = model.init_state(batch_size=x_tokens.size(0), device=device)\n",
    "\n",
    "        for _ in range(n_sup_eval):\n",
    "            y_state, z_state, logits, halt_logit = model.forward_step(\n",
    "                x_tokens, y=y_state, z=z_state, n=N, T=T, k_last_ops=None  # make eval consistent\n",
    "            )\n",
    "\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        em = (preds == y_true).all(dim=1).float()\n",
    "        cell_acc = (preds == y_true).float().mean(dim=1)\n",
    "        em_list.append(em); cell_acc_list.append(cell_acc)\n",
    "\n",
    "    em = torch.cat(em_list).mean().item()\n",
    "    cell_acc = torch.cat(cell_acc_list).mean().item()\n",
    "    print(f\"Validation | Exact-match {em:.3f} | Cell accuracy {cell_acc:.3f}\")\n",
    "    return em, cell_acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.0, betas=(0.9, 0.95))\n",
    "scaler = GradScaler(\"cuda\", enabled=(device.type == \"cuda\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward-only finiteness: y1 True z1 True logits True halt_logit True\n",
      "Pre-backward finiteness: loss True loss_ce True loss_halt True\n",
      "Gradients finite: True\n",
      "Post-step forward finiteness: y2 True z2 True logits2 True halt2 True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# one batch\n",
    "x_tokens, y_true = next(iter(train_loader))\n",
    "x_tokens = x_tokens.to(device)\n",
    "y_true   = y_true.to(device)\n",
    "\n",
    "# forward-only check (no training, no AMP)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y0, z0 = model.init_state(batch_size=x_tokens.size(0), device=device)\n",
    "    y1, z1, logits, halt_logit = model.forward_step(x_tokens, y=y0, z=z0, n=N, T=T, k_last_ops=None)\n",
    "print(\"Forward-only finiteness:\",\n",
    "      \"y1\", torch.isfinite(y1).all().item(),\n",
    "      \"z1\", torch.isfinite(z1).all().item(),\n",
    "      \"logits\", torch.isfinite(logits).all().item(),\n",
    "      \"halt_logit\", torch.isfinite(halt_logit).all().item())\n",
    "\n",
    "# single training step in full FP32 (no AMP, tiny LR, no weight decay)\n",
    "model.train()\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.0)\n",
    "opt.zero_grad(set_to_none=True)\n",
    "\n",
    "y0, z0 = model.init_state(batch_size=x_tokens.size(0), device=device)\n",
    "y1, z1, logits, halt_logit = model.forward_step(x_tokens, y=y0, z=z0, n=N, T=T, k_last_ops=None)\n",
    "\n",
    "# compute losses in fp32\n",
    "loss_ce = F.cross_entropy(logits.float().reshape(-1, OUTPUT_TOKENS), y_true.reshape(-1))\n",
    "em = (logits.argmax(dim=-1) == y_true).all(dim=1).float()\n",
    "loss_halt = F.binary_cross_entropy_with_logits(halt_logit.float(), em)\n",
    "loss = loss_ce + loss_halt\n",
    "\n",
    "print(\"Pre-backward finiteness:\",\n",
    "      \"loss\", torch.isfinite(loss).item(),\n",
    "      \"loss_ce\", torch.isfinite(loss_ce).item(),\n",
    "      \"loss_halt\", torch.isfinite(loss_halt).item())\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "# check grads\n",
    "all_grads_finite = True\n",
    "for n, p in model.named_parameters():\n",
    "    if p.grad is None:\n",
    "        continue\n",
    "    if not torch.isfinite(p.grad).all():\n",
    "        print(\"Non-finite grad in:\", n)\n",
    "        all_grads_finite = False\n",
    "        break\n",
    "print(\"Gradients finite:\", all_grads_finite)\n",
    "\n",
    "# clip and step\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "opt.step()\n",
    "\n",
    "# forward again after one small step\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y0, z0 = model.init_state(batch_size=x_tokens.size(0), device=device)\n",
    "    y2, z2, logits2, halt2 = model.forward_step(x_tokens, y=y0, z=z0, n=N, T=T, k_last_ops=None)\n",
    "print(\"Post-step forward finiteness:\",\n",
    "      \"y2\", torch.isfinite(y2).all().item(),\n",
    "      \"z2\", torch.isfinite(z2).all().item(),\n",
    "      \"logits2\", torch.isfinite(logits2).all().item(),\n",
    "      \"halt2\", torch.isfinite(halt2).all().item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | CE 0.2018 | HaltBCE 0.4367 | Exact-match 0.621\n",
      "Validation | Exact-match 0.609 | Cell accuracy 0.928\n",
      "Epoch 02 | CE 0.1962 | HaltBCE 0.4472 | Exact-match 0.610\n",
      "Validation | Exact-match 0.637 | Cell accuracy 0.929\n",
      "Epoch 03 | CE 0.1807 | HaltBCE 0.4153 | Exact-match 0.641\n",
      "Validation | Exact-match 0.621 | Cell accuracy 0.927\n",
      "Epoch 04 | CE 0.2008 | HaltBCE 0.4212 | Exact-match 0.619\n",
      "Validation | Exact-match 0.650 | Cell accuracy 0.933\n",
      "Epoch 05 | CE 0.2081 | HaltBCE 0.4337 | Exact-match 0.624\n",
      "Validation | Exact-match 0.553 | Cell accuracy 0.917\n"
     ]
    }
   ],
   "source": [
    "# train+eval\n",
    "EPOCHS = 5\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train_one_epoch(model, train_loader, optimizer, scaler, epoch, use_amp=False)\n",
    "    evaluate(model, val_loader, n_sup_eval=N_SUP)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Puzzle 0:\n",
      "[[3 0 1 0]\n",
      " [0 0 0 2]\n",
      " [0 1 2 3]\n",
      " [2 0 0 1]]\n",
      "Pred:\n",
      "[[3 2 1 4]\n",
      " [1 4 3 2]\n",
      " [4 1 2 3]\n",
      " [2 3 4 1]]\n",
      "True:\n",
      "[[3 2 1 4]\n",
      " [1 4 3 2]\n",
      " [4 1 2 3]\n",
      " [2 3 4 1]]\n",
      "\n",
      "Puzzle 1:\n",
      "[[0 0 0 4]\n",
      " [4 0 3 1]\n",
      " [0 4 1 3]\n",
      " [0 1 4 2]]\n",
      "Pred:\n",
      "[[1 3 2 4]\n",
      " [4 2 3 1]\n",
      " [2 4 1 3]\n",
      " [3 1 4 2]]\n",
      "True:\n",
      "[[1 3 2 4]\n",
      " [4 2 3 1]\n",
      " [2 4 1 3]\n",
      " [3 1 4 2]]\n",
      "\n",
      "Puzzle 2:\n",
      "[[0 4 0 1]\n",
      " [0 0 3 4]\n",
      " [0 2 4 3]\n",
      " [4 3 1 0]]\n",
      "Pred:\n",
      "[[3 4 2 1]\n",
      " [2 1 3 4]\n",
      " [1 2 4 3]\n",
      " [4 3 1 2]]\n",
      "True:\n",
      "[[3 4 2 1]\n",
      " [2 1 3 4]\n",
      " [1 2 4 3]\n",
      " [4 3 1 2]]\n",
      "\n",
      "Puzzle 3:\n",
      "[[0 0 4 2]\n",
      " [0 4 3 1]\n",
      " [4 0 1 3]\n",
      " [3 0 0 4]]\n",
      "Pred:\n",
      "[[1 3 4 2]\n",
      " [2 4 3 1]\n",
      " [4 2 1 3]\n",
      " [3 1 2 4]]\n",
      "True:\n",
      "[[1 3 4 2]\n",
      " [2 4 3 1]\n",
      " [4 2 1 3]\n",
      " [3 1 2 4]]\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def solve_and_show(model: TRM, loader: DataLoader, n_batches: int = 1):\n",
    "    model.eval()\n",
    "    shown = 0\n",
    "    for x_tokens, y_true in loader:\n",
    "        x_tokens = x_tokens.to(device)\n",
    "        y_true   = y_true.to(device)\n",
    "        y_state, z_state = model.init_state(batch_size=x_tokens.size(0), device=device)\n",
    "        for _ in range(N_SUP):\n",
    "            y_state, z_state, logits, halt_logit = model.forward_step(\n",
    "                x_tokens, y=y_state, z=z_state, n=N, T=T, k_last_ops=None\n",
    "            )\n",
    "        preds_tok = logits.argmax(dim=-1).cpu().numpy()\n",
    "        xs = x_tokens.cpu().numpy()\n",
    "        ys_tok = y_true.cpu().numpy()\n",
    "        for i in range(min(4, xs.shape[0])):\n",
    "            print(f\"\\nPuzzle {shown+i}:\")\n",
    "            print(xs[i].reshape(4,4))\n",
    "            print(\"Pred:\")\n",
    "            print((preds_tok[i] + 1).reshape(4,4))   # tokens -> digits\n",
    "            print(\"True:\")\n",
    "            print((ys_tok[i] + 1).reshape(4,4))\n",
    "        shown += 1\n",
    "        if shown >= n_batches:\n",
    "            break\n",
    "\n",
    "solve_and_show(model, val_loader, n_batches=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
